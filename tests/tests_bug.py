"""
Test espec√≠fico para identificar el bug exacto
"""
import json
from pyparsejson.core.repair import Repair
from pyparsejson.core.context import Context
from pyparsejson.phases.tokenize import TolerantTokenizer
from pyparsejson.phases.json_finalize import JSONFinalize


def test_simple_case():
    """Test del caso m√°s simple que est√° fallando"""

    text = 'user: "admin", active: si'
    print(f"\n{'=' * 70}")
    print(f"TEST: {text}")
    print(f"{'=' * 70}")

    # PASO 1: Tokenizaci√≥n
    tokenizer = TolerantTokenizer()
    tokens = tokenizer.tokenize(text)

    print(f"\n1Ô∏è‚É£ TOKENIZACI√ìN:")
    print(f"   Cantidad: {len(tokens)}")
    for i, t in enumerate(tokens):
        print(f"   [{i}] {t.type.name:15s} = '{t.value}'")

    # PASO 2: Crear contexto y aplicar SOLO WrapRootObjectRule manualmente
    context = Context(text)
    context.tokens = tokens.copy()

    from pyparsejson.rules.structure.wrappers import WrapRootObjectRule
    wrap_rule = WrapRootObjectRule()

    if wrap_rule.applies(context):
        print(f"\n2Ô∏è‚É£ APLICANDO WrapRootObjectRule:")
        print(f"   Tokens antes: {len(context.tokens)}")
        wrap_rule.apply(context)
        print(f"   Tokens despu√©s: {len(context.tokens)}")

        for i, t in enumerate(context.tokens):
            print(f"   [{i}] {t.type.name:15s} = '{t.value}'")

    # PASO 3: Aplicar AddMissingCommasRule
    from pyparsejson.rules.structure.separators import AddMissingCommasRule
    comma_rule = AddMissingCommasRule()

    if comma_rule.applies(context):
        print(f"\n3Ô∏è‚É£ APLICANDO AddMissingCommasRule:")
        print(f"   Tokens antes: {len(context.tokens)}")
        comma_rule.apply(context)
        print(f"   Tokens despu√©s: {len(context.tokens)}")

        for i, t in enumerate(context.tokens):
            print(f"   [{i}] {t.type.name:15s} = '{t.value}'")

    # PASO 4: Finalizar
    finalizer = JSONFinalize()
    json_text = finalizer.process(context)

    print(f"\n4Ô∏è‚É£ FINALIZACI√ìN:")
    print(f"   JSON generado: {json_text}")
    print(f"   Longitud: {len(json_text)}")

    # PASO 5: Parse
    try:
        obj = json.loads(json_text)
        print(f"\n5Ô∏è‚É£ PARSING:")
        print(f"   ‚úÖ SUCCESS")
        print(f"   Objeto: {obj}")
    except json.JSONDecodeError as e:
        print(f"\n5Ô∏è‚É£ PARSING:")
        print(f"   ‚ùå ERROR: {e}")

    # PASO 6: Comparar con pipeline completo
    print(f"\n6Ô∏è‚É£ PIPELINE COMPLETO:")
    repair = Repair(auto_flows=True)
    report = repair.parse(text)
    print(f"   Success: {report.success}")
    print(f"   JSON: {report.json_text}")
    print(f"   Object: {report.python_object}")

    # DIAGN√ìSTICO FINAL
    print(f"\n{'=' * 70}")
    if report.python_object == {}:
        print("‚ö†Ô∏è CONFIRMADO: El pipeline completo retorna objeto vac√≠o")
        print("üîç Causas posibles:")
        print("   1. Los tokens se vac√≠an en alg√∫n punto del flujo")
        print("   2. El finalizador no est√° procesando los tokens")
        print("   3. Hay un error en json.loads() que se captura silenciosamente")
    else:
        print("‚úÖ El pipeline funciona correctamente")
    print(f"{'=' * 70}")


if __name__ == "__main__":
    test_simple_case()